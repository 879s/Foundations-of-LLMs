# 大模型基础

毛玉仁 高云君等 著

<img src=".\figure\cover.png" alt="cover" style="zoom:10%;" />

## 章节内容

**第一章 语言模型基础**
本章按照语言模型发展的顺序依次讲解基于统计方法的 n-grams 语言模型、基于 RNN 的语言模型，基于 Transformer 的语言模型。此外，本章还介绍了如何将语言模型输出概率值解码为目标文本，以及如何对语言模型的性能进行评估。

**第二章 大语言模型**
本章介绍了 Encoder-only、Encoder-Decoder 以及 Decoder-only 三种主流架构的大模型。深入分析了它们的模型架构、训练方法以及主要创新之处等。最后，本章还介绍了其他一些具有创新性的架构模型。

**第三章 Prompt工程**




**第四章 参数高校微调**
本章给出了参数高效微调的概念和分类学，详细介绍了参数高效微调的三类主要方法，包括参数附加方法、参数选择方法和低秩适配方法，探讨它们具体的技术实现和优势。最后，本章还通过具体案例展示 PEFT 在垂直领域的实际应用。

**第五章 模型编辑**



**第六章 检索增强生成**
本章首先介绍 RAG 系统的相关背景、定义以及基本组成，接下来详细介绍了RAG 系统的常见架构，随后我们展开讨论 RAG 系统中知识检索与生成增强部分的技术细节，最后，本章还简要介绍了 RAG 系统的应用与前景。

## 作者分工

本书作者分工情况如下：

- 第一章作者为：毛玉仁、高云君；
- 第二章作者为：李佳晖、毛玉仁、宓禹；
- 第三章作者为：张超、胡中豪、毛玉仁；
- 第四章作者为：葛宇航、毛玉仁；
- 第五章作者为：宓禹、樊怡江、毛玉仁；
- 第六章作者为：董雪梅、徐文溢、毛玉仁。

高云君为本书编撰总指导。

## 引用

```
毛玉仁, 高云君, 李佳晖, 宓禹, 张超, 胡中豪, 葛宇航, 樊怡江, 董雪梅, 徐文溢. (2024). 大模型基础. 浙江大学. https://github.com/ZJU-LLMs/Foundations-of-LLMs
```

```
@book{FoundationsofLLMs,
  title = {大模型基础},
  author = {毛玉仁 and 高云君 and 李佳晖 and 宓禹 and 张超 and 胡中豪 and 葛宇航 and 樊怡江 and 董雪梅 and 徐文溢},
  year = {2024},
  address = {杭州},
  url = {https://github.com/ZJU-LLMs/Foundations-of-LLMs},
}

```



