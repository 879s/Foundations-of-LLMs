# Training Large Language Models to Reason in a Continuous Latent Space

*Shibo Hao, Sainbayar Sukhbaatar* 等

*Meta, UC San Diego 等*

本文提出了一种新的推理框架Coconut（Chain of Continuous Thought），旨在通过让大语言模型（LLM）在连续潜在空间中进行推理，突破传统语言空间的限制。与链式思维（CoT）不同，Coconut利用LLM的最后一个隐状态作为推理状态（称为“连续思维”），并将其作为后续输入，而不是将其解码为文本标记。通过这一创新方法，Coconut能够执行更灵活、更高效的推理过程，尤其在需要规划和回溯的任务中表现更为优越。

### 研究内容

研究新的大语言模型推理范式 “连续思维链”（Coconut），旨在让模型在连续潜在空间中进行推理，而非仅限于自然语言空间。

### 研究动机

传统的显式推理如CoT要求LLM在语言空间中逐步生成推理过程。然而，脑科学研究表明，人类在进行推理时，大脑的语言网络并非总是活跃，这意味着语言可能并非最优的推理媒介。此外，CoT为每个生成的token分配相同的计算资源，但实际上，不同token所需的推理复杂度各不相同。

### 技术动机

在CoT中，大部分token仅用于保持文本流畅，对实际推理贡献有限，而某些关键token则需要复杂的规划，给LLM带来巨大挑战。因此，可以让**LLM在不受语言限制的潜在空间中进行推理，仅在必要时将结果转化为语言**。

### 解决方案

1. **模型架构**：连续思维链（Coconut）将LLM的**最后一个隐藏状态**视为“连续思维”的表示，直接将其作为下一个输入的嵌入，而不是解码为token。这样，模型可以在潜在空间中进行推理，而无需生成中间的语言表达。

![](https://fastly.jsdelivr.net/gh/bucketio/img15@main/2024/12/17/1734416728519-82104b03-87a8-44d5-9ec0-e58f0c419611.png)

2. **训练过程**：

   Coconut 采用多阶段渐进式训练策略，逐渐使用连续思维替换原始语言推理步骤，并使用<bot>和<eot>包裹连续思维。

   - **初始阶段**：模型使用传统的链式思维（CoT）生成语言推理链。
   - **后续阶段**：逐步增加潜在推理步骤，减少语言推理步骤。每个阶段用连续思维替代语言推理，通过隐状态指导推理。
   - **训练目标**：优化负对数似然损失，并对**输入问题和连续思维**进行掩码。

![](https://fastly.jsdelivr.net/gh/bucketio/img1@main/2024/12/17/1734416758960-0042e687-c82f-452b-ab45-d9b223812961.png)

3. **推理过程**：Coconut推理和标准的语言模型解码过程类似。不同之处在于，在潜在模式下，模型直接将最后的隐状态作为输入嵌入进行推理。LLM根据设定的标记（如\<bot\>和\<eot\>）在语言模式和连续推理模式之间切换。

### 实验结果

实验表明，Coconut在多个推理任务中有效增强了LLM的性能。在需要大量回溯规划的逻辑推理任务中，Coconut比CoT表现更优，且在推理过程中生成的token更少。

![](https://fastly.jsdelivr.net/gh/bucketio/img9@main/2024/12/17/1734416837301-e8c55ada-2970-4e5f-9279-056283ee1cf9.png)

综上，Coconut 引入一种新的LLM推理范式—潜在空间推理，突破了传统语言空间推理的局限性。多阶段训练策略和潜在思维的端到端优化，使得Coconut在处理复杂推理任务时，能够更灵活地进行推理，并在效率和准确性上超越了传统的链式思维（CoT）方法。

---

- 查看 Arxiv 原文请点击"**阅读原文**"[https://arxiv.org/abs/2412.06769]
- **更多**大模型学习资料，详见浙江大学LLMs Github仓库: 
  https://github.com/ZJU-LLMs/Foundations-of-LLMs
- 本文编辑：葛宇航，毛玉仁