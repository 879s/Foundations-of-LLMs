 # GME: Improving Universal Multimodal Retrieval by Multimodal LLMs

  作者：Xin Zhang, Yanzhao Zhang等

  单位：Tongyi Lab, Alibaba Group  The Hong Kong Polytechnic University等

本文研究了通用多模态检索（GME），为解决现有训练数据中模态不平衡的问题，本文提出了一种用于混合模态数据合成的pipeline，构建了大规模、高质量的融合模态数据集，并在此基础上训练开发了通用多模态检索模型和新的评估基准-UMR Benchmark。

  ## 研究内容

  **通用多模态检索器**，本文指可以接受文本或图片输入或者图文组合输入的检索器，检索对象也包括图片或者文本，或者图文对象。

  ## 研究动机

现有方法使用的训练数据模态受限且模态不平衡，无法充分发挥多模态大模型在通用多模态检索中的潜力，此外通用多模态检索任务的多模态、多场景需求尚未得到全面评估，缺乏一个全面的评测基准。

  ## 技术动机

1.多模态大模型已经在多模态信息理解和推理方面展现了令人瞩目的进展，其内部对多模态数据有优秀的表征。2.使用LLM和MLLM来合成数据已有先例。

  ## 解决方案


![](https://fastly.jsdelivr.net/gh/bucketio/img6@main/2024/12/27/1735295897376-b1d34a42-4ee1-4547-9db6-e5703a5e144f.png)

**模型架构**：使用 MLLM 作为通用多模态检索器的基座模型。MLLM接收图像、文本或图文组合的输入，将模型最后一层的隐藏状态中的最终token作为输入的表示，并使用对比学习进行训练，使模型适应检索任务。

**训练数据**：为了解决训练数据中模态不平衡的问题，特别是**融合模态数据**稀缺，本文使用 LLM 和 MLLM 的生成能力来合成额外的训练数据，其合成步骤分为以下四步：

**Doc2Query 生成**：将每条候选段落的内容输入到一个 LLM 中，并通过提示生成基于段落的自然查询。

**实体抽取与查询重写**：为了使合成的查询同时包含文本和图像（即 IT→IT 类型），采用实体抽取的方法，通过抽取的实体补充图像数据。

**图像检索与生成**：通过 Google Image Search API 检索与实体词条匹配的图像或者通过 **文本生成图像模型** 生成图像。

**数据过滤**：为了确保合成数据的质量，对最终数据集进行了过滤。

  ## 实验结果

实验上，本文将所训练的通用多模态检索器与 **VISTA** ， **E5-V** 等方法在**单模态**检索，跨模型检索，以及融合模态检索的对比结果如下图所示：

![](https://fastly.jsdelivr.net/gh/bucketio/img18@main/2024/12/27/1735295924667-fc7a5e41-847c-4b30-aa75-759f06da7aff.png)


此外，本文在**微调策略**，训练策略以及是否开启双向注意力上进行了消融实验，实验结果如下图所示：

![](https://fastly.jsdelivr.net/gh/bucketio/img5@main/2024/12/27/1735295954238-1096c45d-45d0-4668-a9e3-b3849224ea26.png)


综上，本文探索了**通用多模态检索**问题，通过在多样化的多模态数据设置上采用对比学习损失进行训练，达到了最新的最先进性能。


---

  - 查看 Arxiv 原文请点击"**阅读原文**"[https://arxiv.org/abs/2410.10630v1]
  - **更多**大模型学习资料，详见浙江大学LLMs Github仓库: 
    https://github.com/ZJU-LLMs/Foundations-of-LLMs
  - 本文编辑：胡中豪，毛玉仁