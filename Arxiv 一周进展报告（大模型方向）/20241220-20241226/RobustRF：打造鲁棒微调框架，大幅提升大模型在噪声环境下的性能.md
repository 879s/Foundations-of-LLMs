# RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response

*Junyu Luo, Xiao Luo 等*

*Peking University, University of California, Los Angeles 等*

本文提出了一种名为 RobustFT 的鲁棒监督微调框架，旨在缓解大语言模型（LLM）在噪声数据环境下性能下降的问题。通过多专家协作系统和推理增强机制进行噪声检测，并结合上下文增强的重标注策略和基于熵的样本选择机制实现降噪，RobustFT 构建了一个高质量的微调数据集，从而显著提升模型在下游任务中的性能。实验结果表明，该框架在多个数据集和噪声比例下均表现出色，展示了其鲁棒性和广泛适用性。RobustFT 为 LLM 在实际应用中处理噪声数据提供了有效解决方案。

## 研究内容

研究针对大语言模型在噪声环境中进行监督微调的鲁棒方法。

## 研究动机

现有的监督微调方法在处理包含噪声的数据时表现较差，这导致模型在下游任务中的性能严重下降；同时，传统的降噪方法无法有效应用于上下文丰富的开放式文本生成任务。

## 技术动机

通过多专家协作和推理增强机制，结合上下文增强的降噪策略，可以更好地检测噪声并提高数据质量，从而改善模型的下游任务性能。

## 解决方案

**RobustFT** 的解决方案通过**噪声检测**与**数据降噪**两个阶段，构建一个高质量、低噪声的微调数据集，从而增强大语言模型（LLM）的鲁棒性和性能。

![](https://fastly.jsdelivr.net/gh/bucketio/img3@main/2024/12/27/1735262919524-e2e434b3-c091-44ce-bde4-95c0da567949.png)

#### **噪声检测**

噪声检测的目标是识别数据集中潜在的噪声样本，具体方法如下：

1. **多专家协作机制**

   利用多个专家模型（包括基础模型和推理增强模型）对同一数据进行预测。

2. **推理增强策略**

   通过模型的推理能力增强噪声检测：

   - 逐步推理：让模型逐步生成预测结果，确保过程透明且可分析。
   - 自我反思：模型在推理后对其过程进行自我审查，优化推理路径。

3. **一致性检测**

   比较基础预测结果、推理增强结果与原始标签的一致性。使用一致性度量（Checker）评估样本的可靠性：如果预测结果高度一致，则标记为可靠样本（Clean Data）；如果结果不一致，则标记为潜在噪声样本（Noisy Data）。

#### **数据降噪**

数据降噪的目标是对潜在噪声样本进行处理，生成更可靠的标签，具体包括以下步骤：

1. **上下文增强重标注**

   - **上下文增强预测**：利用高置信度的可靠数据（Clean Data）为噪声样本（Noisy Data）提供上下文支持。将潜在噪声样本与可靠样本映射到相同的特征空间。检索与噪声样本最相似的高置信度样本，作为上下文支持。基于上下文支持生成新的标签。
   - **重标注过程**：通过一个复核代理（Reviewer Agent）对新标签进行评估，结合上下文增强预测与推理增强预测，生成最终的降噪标签。

2. 基于熵的样本选择

   为了进一步确保数据质量，对所有降噪后的样本计算预测熵值。根据模型的预测分布，衡量样本的不确定性。样本熵值越低，预测越确定，质量越高。根据熵值对样本排序，选取熵值最低的前 β% 样本（默认 β=50%）作为最终的高质量微调数据。

####  **框架整合**

RobustFT 将可靠样本和经过降噪筛选的样本合并为最终的微调数据集，并基于该数据集对模型进行监督微调。

### 实验结果

本文的实验在五个数据集上进行了验证，包括通用任务（如 **MMLU** 和 **ARC**）以及特定领域任务（如 **PubMedQA**、**Drop** 和 **FPB**），并在不同噪声水平（30%、50%、70%）下进行了全面比较。以下是主要实验结果：

![](https://fastly.jsdelivr.net/gh/bucketio/img9@main/2024/12/27/1735262818558-247aa2fd-f590-4d63-811c-79d9c9b29199.png)

与 Vanilla 和标准 SFT 方法相比，RobustFT 在所有噪声水平和数据集上均表现出更高的鲁棒性和更好的性能。实验还评估了不同规模的模型，包括 **Llama3.2 (3B)**、**Llama3.1 (8B)** 和 **Gemma2 (9B)**，并在不同噪声水平下验证了 ROBUSTFT 的普适性：

![](https://fastly.jsdelivr.net/gh/bucketio/img19@main/2024/12/27/1735262890193-a17b56a0-6105-426f-82b0-8d79be7b5bad.png)

RobustFT 对不同规模和架构的模型均有效，尤其对小模型的噪声鲁棒性提升更加显著。

综上， RobustFT 专注于解决大语言模型（LLM）在噪声数据环境中的性能下降问题。通过多专家协作机制、推理增强策略、上下文增强重标注和基于熵值的样本选择，RobustFT 实现了从噪声检测到降噪的高效流程，显著提升了微调数据的质量和模型的下游任务性能。

---

- 查看 Arxiv 原文请点击"**阅读原文**"[https://arxiv.org/abs/2412.14922]
- **更多**大模型学习资料，详见浙江大学LLMs Github仓库: 
  https://github.com/ZJU-LLMs/Foundations-of-LLMs
- 本文编辑：葛宇航，毛玉仁