# Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment

_Ziang Yan, Zhilin Li , Yinan He Chenting Wang , Kunchang Li , Xinhao Li , Xiangyu Zeng Zilei Wang , Yali Wang ,Yu Qiao , Limin Wang , Yi Wang_

_Shanghai AI Laboratory_

现有的多模态大语言模型（MLLMs），如LLaVA和VideoChat，在处理视觉任务时，虽然展现出一定的推理和理解能力，但在细粒度视觉任务（如时间片段定位、目标跟踪和像素分割）上表现仍然不足。这主要是由于视觉任务需求与语言表征之间的冲突，难以同时兼顾精细预测与多模态推理性能。因此，本文提出了**任务偏好优化（Task Preference Optimization, TPO）**方法。该方法通过引入可学习的任务tokens和任务头架构，结合分阶段多模态训练策略，显著提升了模型在精细化视觉任务和多模态对话中的综合能力，同时保持较高的计算效率。

## 研究内容

本文研究如何设计一种新框架，使得多模态模型能够处理精细化的视觉任务（如时间定位、分割）并提升多模态对话能力。

## 研究动机

当前 MLLMs 在视觉推理任务中表现出色，但在处理精细化的视觉任务（如区域定位和时间片段标注）时能力不足，且现有方法常以牺牲整体多模态性能为代价来优化单一任务。

## 技术动机

跨任务联合训练有互补效应，但视觉预测与语言表征存在冲突，因此需要设计解耦的任务表征来解决。

## 解决方案

![](https://fastly.jsdelivr.net/gh/bucketio/img7@main/2025/01/02/1735808763755-37759edd-05d3-4b8f-9728-4f626dd26811.png)

#### 任务偏好模型（TPM）设计

任务偏好模型（TPM）由**任务tokens**和**任务头**组成，用于处理不同的视觉任务需求。

**任务tokens：**

- 任务 tokens 是可学习的嵌入，模型通过语言输入动态激活相应的任务token。任务tokens 通过语言模型的最后一层隐藏层嵌入生成任务特定表示.

**任务头：**

任务头负责根据输入视觉特征和任务嵌入执行特定任务：

- **区域头（Region Head）**：基于两层多层感知机（MLP），用于回归边界框坐标，完成空间定位任务。
- **时间头（Temporal Head）**：结合视频编码器、文本编码器和时间定位模型，用于时间片段标注任务，输出开始和结束时间。
- **掩码头（Mask Head）**：通过像素级解码器生成目标掩码，用于分割任务。

任务头通过任务嵌入连接到视觉特征，形成紧密的任务特定优化。

#### 任务偏好优化目标

TPO 的优化目标整合了多模态对话任务和视觉任务，损失函数定义为：
$$
L = L_{\text{mllm}} + L_{\text{assign}}(G(T_q), s) + \sum_{i=1}^n L_{\text{task}}(A_i, H_i(G(v_i)))
$$

- $L_{\text{mllm}}$：多模态对话任务的最大似然损失。
- $L_{\text{assign}}(G(T_q), s)$：任务分配损失，基于用户输入指令 $T_q$ 和任务标签 $s$，使用交叉熵损失进行优化。
- $L_{\text{task}}(A_i, H_i(G(v_i)))$：任务优化损失，针对不同视觉任务使用分类或回归相关损失：
  - 如区域任务采用边界框回归损失；
  - 时间任务采用时间片段回归损失；
  - 掩码任务采用像素级交叉熵损失。

#### **分阶段训练策略**

TPO 使用分阶段的本地到全局训练策略，确保模型在任务识别、单任务性能和多任务能力上的逐步优化。

**阶段1：任务分配阶段**

- 让模型能够识别用户输入中的任务类型，并动态激活相应的任务Tokens。使用 LoRA微调语言模型，确保任务token与任务头之间的激活准确性。

**阶段2：单任务优化阶段**

- 提高模型在单一视觉任务（如区域定位、时间标注或像素分割）上的性能。模型更新方向仅限于任务头和任务token，确保单任务的局部优化。

**阶段3：多任务联合优化阶段**

- 整合多模态对话数据和视觉任务数据，提升模型在多任务场景下的综合能力。

## 实验结果

在实验设计中，研究者选择了多个主流的多模态理解基准测试，如 MVBench、VideoMME 和 MLVU 等，用于全面验证 TPO 的有效性。实验结果表明，TPO 在多种视觉任务中展现了显著的性能提升：

- **时刻检索**：在多个基准测试中，VideoChat-TPO 超越了现有的最先进模型，表现出卓越的时间段定位能力，尤其是在需要复杂推理的场景中展现了明显优势。
- **高亮检测**：TPO 显著增强了模型在关键时刻识别和定位任务中的表现，有效处理动态视觉信息并提取重要内容。
- **空间定位**：通过实验验证，TPO 在文本指导下生成边界框的能力得到了显著提升，展现了模型在精细化空间定位任务中的优越性能。

![](https://fastly.jsdelivr.net/gh/bucketio/img16@main/2025/01/02/1735808851889-90da9203-6b1b-4a6a-a8d6-efa3ba8a1911.png)

---

- 查看 Arxiv 原文请点击"**阅读原文**"[https://arxiv.org/pdf/2412.19326v1]
- **更多**大模型学习资料，详见浙江大学LLMs Github仓库: 
  https://github.com/ZJU-LLMs/Foundations-of-LLMs
- 本文编辑：徐文溢，毛玉仁