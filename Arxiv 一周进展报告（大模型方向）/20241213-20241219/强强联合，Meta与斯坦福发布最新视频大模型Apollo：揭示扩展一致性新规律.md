- - # Apollo: An Exploration of Video Understanding in Large Multimodal Models

    Orr Zohar , Xiaohan Wang等

    Meta GenAI, Stanford University等

    本文研究了影响视频多模态大模型性能的主要因素，并发现了**扩展一致性**：即在较小的模型和数据集上做出的设计和训练决策能够有效地转移到较大的模型上。在这些发现的指导下，本文推出了**Apollo**，一系列先进的视频多模态大模型，在不同模型规模下实现了卓越的性能。

    ## 研究内容

    视频多模态大模型

    ## 研究动机

    尽管大量多模态大模型已经有视频感知能力，但其驱动视频理解的底层机制仍然没有得到充分探索。许多设计决策在这一领域中常常缺乏充分的论证和分析。训练和评估这类模型的高计算成本，加上开放研究的局限性，阻碍了视频多模态大模型的发展。

    ## 技术动机

    基于实验探索设计技巧，在模型架构设计，训练策略，数据组成上进行大量实验，采用最适合视频多模态大模型的技术。

    ## 解决方案

    首先，本文对现有的视频基准进行广泛的评估，发现现有视频问答基准之间存在显著的冗余性，尤其是在不同的视频时长和问题格式之间，高相关性表明，现有的基准可能存在重复性，并且不同视频时长和问题类型对评估结果的多样性贡献有限。所以基于这些见解，本文开发了一个更高效、更有效的基准套件——**ApolloBench**， 在**ApolloBench**上的评估速度是传统基准的41倍，并且更能反映模型的视频理解能力。

    然后，为了探索视频多模态大模型的扩展一致性，以及视频多模态大模型的架构设计，视频编码器选择，视频帧采样策略，视频token压缩方法，训练策略，数据选择等等对视频多模态大模型性能的影响，本文训练了84个模型，进行了大量的实验。

    最后，在基于大量实验分析的基础上，本文提出了**Apollo**系列，取得了在视频理解方面的最先进成果。
  
    ## 实验结果
  
    实验上，具体来说，本文设计了21个模型变体，涵盖了架构、视频采样方法、训练策略和数据组合等多个设计方面，每个变体使用四个不同的大型语言模型（LLMs）：Qwen2-0.5B、Qwen2-1.5B、Qwen1.5-4B和Qwen2-7B，总共训练了84个模型。
  
    ![](https://fastly.jsdelivr.net/gh/bucketio/img2@main/2024/12/22/1734859524947-730cbd0a-6e83-48ac-969c-918bd9507784.png)
  
  
    基于以上实验，本文发现了**扩展一致性**，发现在中等规模的模型（约2B到4B参数）和500k大小以上规模的数据集上做出的设计决策，可以可靠地迁移到更大的模型上，而在更小的模型（比如0.5B）和更小的数据集中则未观察到。
  
    此外在模型设计以及数据组合等多方面，本文有以下发现：
  
    1. **视频采样**：在模型训练和推理过程中，相较于均匀采样，FPS采样更为优秀（均匀采样指在帧维度采样，而FPS是在时间维度上进行帧采样）。同时在每秒帧采样数目和帧token压缩之间存在一个平衡，8-32个token每帧是最优的配置。
    2. **视频表征**：在实验InternVideo2, LanguageBind-Video v1.5， VideoMAE 等编码器后发现，**SigLIP-SO400M** 是视频-LMMs中最好的单一编码器。将**SigLIP-SO400M**与**InternVideo2**结合，能够实现最优的整体性能。来自不同帧或剪辑的视频标记之间添加token（时间戳或特殊token等）足以实现高效的token集成。
    3. **训练策略**：在不同阶段逐步解冻不同的组件可以实现更优的模型训练。三阶段训练能获得最佳性能，其次是两阶段训练计划。需要注意的是，不同的阶段有不同的数据组成；具体而言，每当LLM被冻结时，其他组件仅在视频数据上进行调优，而当LLM被调优时，则使用文本、图像、多图像和视频的混合数据集。仅在视频数据上微调视频编码器进一步提升了整体性能，特别是在推理和领域特定任务上的表现。如果视频编码器和LLM同时解冻，视觉编码器将在图像和视频数据的组合上进行训练会显著降低模型性能。而单独在视频数据上训练编码器会更优。
    4. **数据组合**：适量的文本数据和略微偏向视频的数据组合有助于达到最佳性能。在训练数据混合中包含10% ~ 14%的文本数据是必要的，这有助于缓解灾难性遗忘。当文本数据的比例超过14%或低于7%时，模型性能会受到损害。
  
    最后基于以上发现，本文开发了**Apollo**视频多模态大模型，其表现如下：
  

    ![](https://fastly.jsdelivr.net/gh/bucketio/img6@main/2024/12/22/1734859544714-7deef02a-89ee-4210-aa2f-c0664154abdc.png)
  
  
    ---
  
    - 查看 Arxiv 原文请点击"**阅读原文**"[https://arxiv.org/abs/2410.10630v1]
    - **更多**大模型学习资料，详见浙江大学LLMs Github仓库: 
      https://github.com/ZJU-LLMs/Foundations-of-LLMs
    - 本文编辑：胡中豪，毛玉仁