# RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation

_Xiaoxi Li, Zhicheng Dou 等_

_Gaoling School of Artificial Intelligence, Renmin University of China, Tsinghua University, Huawei Poisson Lab 等_

本文研究的是**如何在生成式检索的视角下，将检索增强过程整合到大语言模型的自回归解码过程中以提升答案准确性**。现有检索增强生成（RAG）方法在处理大语言模型生成过程时存在诸多局限，如增加部署成本、输入冗余、缺乏联合优化等，难以在检索与生成间达成高效协同。为此本文提出了**生成式检索框架 RetroLLM **，通过构建**语料库级和文档级 FM - Index **进行分层约束以减少无关解码空间，**通过前瞻性约束证据生成**定位相关信息以提高证据准确性，有效提升大语言模型在开放域问答任务中的答案准确性，增强模型在实际应用中的可靠性与有效性。 

## 研究内容
研究在生成式检索中，如何将检索增强过程整合到大语言模型的自回归解码过程中，包括如何构建分层 FM - Index 约束机制来优化检索空间并定位潜在相关信息，如何优化证据生成以提高准确性，以及探索联合训练方法使检索与生成任务协同优化等。

## 研究动机
现有 RAG 方法存在诸多局限，如部署成本较高、检索文本冗余、灵活性受限及难以联合优化检索与生成等。生成式检索方法虽有进展，但仍需提升检索与生成的集成度，并且存在错误剪枝等问题，影响下游任务性能。

## 技术动机
在生成式检索中，借助分层 FM-Index 与前瞻性解码策略优化检索生成过程。其中分层 FM - Index 可从结构上对检索空间进行有效约束，减少无关解码干扰；前瞻性解码策略则基于对未来序列相关性的感知，避免错误剪枝，提升证据生成的准确性，两者结合以实现检索与生成的高效协同。

## 解决方案

![](https://fastly.jsdelivr.net/gh/bucketio/img9@main/2024/12/18/1734488790478-93a2f28b-4d5d-40bf-9d01-002080109f82.png)

提出了**生成式检索框架 RetroLLM **，将检索与生成紧密结合在一个自回归解码过程中，其主要流程如下：

##### 1. 线索生成阶段

系统首先接收用户输入的查询，随后利用基于整个语料库构建的**语料库级 FM-Index** 来引导线索生成。具体而言，大语言模型依据对查询的理解，尝试生成可能出现在相关文档中的关键短语作为线索（clues），语料库级 FM-Index 起到约束作用，只有那些在语料库中实际存在的短语才能被视作有效的线索。

##### 2. 证据生成阶段
证据生成阶段主要分为以下几步：

- **文档检索与评分**：基于生成的线索，从语料库中检索包含这些线索的文档。接下来对文档进行评分，评估指标包括线索在文档中的出现频率、分布情况等。随后根据评分排名确定一个候选文档子集，作为后续生成证据的基础。

- **前瞻性约束解码证据生成**：生成针对每个候选文档，都有对应的文档级 FM-Index ，通过文档级 FM-Index 能快速定位线索在候选文档中的位置，缩小无关的解码空间。具体步骤如下：

    1）**定位未来窗口**：对于每个线索，在文档中确定包含该线索的未来窗口，即线索周围的一段文本范围，将模型的注意力聚焦在可能包含与线索相关证据的区域。

    2）**评估窗口相关性**：对定位到的未来窗口，通过计算其内部文本与查询之间的语义相似度来评估相关性。

    3）**调整解码logits**：根据窗口相关性的评估结果，调整解码logits。如果某个未来窗口相关性高，就提高该窗口内词汇的生成概率，使生成的证据更倾向于来自这些高相关性的未来窗口。

##### 3. 答案生成阶段
在前面成功生成证据的基础上，模型再次发挥其生成能力，依据这些证据内容来生成最终的答案，以回答最初用户输入的查询。

## 实验结果
在域内任务（如 NQ、TriviaQA、HotPotQA 数据集）和域外任务（如 PopQA、2WIKI 数据集）中，RetroLLM 均表现出色，优于传统的 RAG 方法。此外，RetroLLM 显著减少了Token消耗，这是因为 RetroLLM 能够精准检索细粒度证据，并动态决定检索证据的数量。

![](https://fastly.jsdelivr.net/gh/bucketio/img11@main/2024/12/22/1734849755723-4d2df1a6-3c0d-4e51-b1ba-dc6090d78a68.png)

---

- 查看 Arxiv 原文请点击"**阅读原文**"[https://arxiv.org/pdf/2412.11919]
- **更多**大模型学习资料，详见浙江大学LLMs Github仓库: 
  https://github.com/ZJU-LLMs/Foundations-of-LLMs
- 本文编辑：董雪梅，毛玉仁